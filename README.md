# AI-Gesture-Control-Car-Using-Machine-Learning-in-Edge-Impulse-
Designed and developed a smart robotic car controlled via hand gestures, integrating Edge Impulse for real-time gesture recognition using machine learning. The project leverages accelerometer sensor data from a microcontroller (Arduino/node mcu) to classify gestures like forward, backward, left, and right.Trained custom ML models on Edge Impulse by collecting motion data, preprocessing signals, and deploying the model directly onto the microcontroller. Enabled gesture updates on the fly by retraining the model with new gesture data and re-deploying, making the system adaptable and scalable.
